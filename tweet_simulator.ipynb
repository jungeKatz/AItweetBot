{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweet_simulator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bAdAgnNSdPQ5HsLfZUWajYUdN0C1N_E-",
      "authorship_tag": "ABX9TyM1OAtuC+wxmitvaHpHO3m0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jungeKatz/AItweetBot/blob/main/tweet_simulator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajw-yKqfOzt5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxvqchyXYx2S",
        "outputId": "4dfce07b-d310-406e-a11a-1a3f139a3151"
      },
      "source": [
        "with open('/content/drive/MyDrive/nlp/extract.txt', 'r') as file:\n",
        "    text = file.read().lower()\n",
        "print('text length', len(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text length 4576053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgyyU5wMaTT0",
        "outputId": "fe141edb-34bc-409c-fa27-24830cc747b0"
      },
      "source": [
        "print(text[:250])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "painful to see the devastating impact of extreme weather in western  with the unprecedented loss of life &amp; destructio n of property. may the world unite in preventing such climatic upheavals by investing in regenerating the planet. â€“ sg what happ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgMEHZMGaZFu",
        "outputId": "6ba86c55-fd2a-444e-c334-6ee7dafae075"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "499 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAYgDNKya88f",
        "outputId": "2fff0de0-050a-49fd-e612-5a635379a638"
      },
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKnAQVi7aiqu"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4rKQ0nbaprM",
        "outputId": "fea51caf-2150-431e-c924-ce77e57947b1"
      },
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[37, 38, 39, 40, 41, 42, 43], [60, 61, 62]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNSi5aGBbJd4"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wvmvuDvbLZf",
        "outputId": "357d6e7c-87dd-48be-9377-a988074ecc9a"
      },
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9qB48nTbTKP",
        "outputId": "3f6e4277-cd74-473a-8d4c-1ad27d5dc32b"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp28tjUFbVew"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HZGyxeNbZvP",
        "outputId": "683ca42c-7f54-41b3-d639-9a04576b0708"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4576053,), dtype=int64, numpy=array([52, 37, 45, ..., 50,  2,  2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5z-dVFJbhX1"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GAPE6dObjZX",
        "outputId": "15b084be-4f0a-4c47-c577-bfe1ffc6dd3d"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p\n",
            "a\n",
            "i\n",
            "n\n",
            "f\n",
            "u\n",
            "l\n",
            " \n",
            "t\n",
            "o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMhnGH2CbpRD"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwrw238AbtvN",
        "outputId": "87e4e764-33da-4e31-95a2-be8c2c96f731"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'p' b'a' b'i' b'n' b'f' b'u' b'l' b' ' b't' b'o' b' ' b's' b'e' b'e'\n",
            " b' ' b't' b'h' b'e' b' ' b'd' b'e' b'v' b'a' b's' b't' b'a' b't' b'i'\n",
            " b'n' b'g' b' ' b'i' b'm' b'p' b'a' b'c' b't' b' ' b'o' b'f' b' ' b'e'\n",
            " b'x' b't' b'r' b'e' b'm' b'e' b' ' b'w' b'e' b'a' b't' b'h' b'e' b'r'\n",
            " b' ' b'i' b'n' b' ' b'w' b'e' b's' b't' b'e' b'r' b'n' b' ' b' ' b'w'\n",
            " b'i' b't' b'h' b' ' b't' b'h' b'e' b' ' b'u' b'n' b'p' b'r' b'e' b'c'\n",
            " b'e' b'd' b'e' b'n' b't' b'e' b'd' b' ' b'l' b'o' b's' b's' b' ' b'o'\n",
            " b'f' b' ' b'l'], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_QRUrwfbx_2",
        "outputId": "6b045a83-d165-49bf-d60a-c3847063f6df"
      },
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'painful to see the devastating impact of extreme weather in western  with the unprecedented loss of l'\n",
            "b'ife &amp; destructio n of property. may the world unite in preventing such climatic upheavals by inve'\n",
            "b'sting in regenerating the planet. \\xe2\\x80\\x93 sg what happens within us is never determined by what is happenin'\n",
            "b'g around us. but unfortunately, we link it to what is happening around us.  serpents\\nmost maligned cr'\n",
            "b'eatures in all of divine creation.\\nthese gentle, colorful beings to me have not only\\nbeen dear but de'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "615otLw0b4Hi"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZM2xNPQb7yf",
        "outputId": "fe08a9f7-1970-41a3-b53c-7e51bc372e64"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM7OVZsjb__8"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMZZ_oOscQ3G",
        "outputId": "21d1bfb3-d03b-4448-f1d3-e717fd99f851"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'painful to see the devastating impact of extreme weather in western  with the unprecedented loss of '\n",
            "Target: b'ainful to see the devastating impact of extreme weather in western  with the unprecedented loss of l'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_StIYKJcV2M",
        "outputId": "638556cd-d1e7-4c7e-bf54-af0c5b122e0a"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4Qtlv0GcbeV"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mat2ALNQchaL"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynz_3NfMclpl"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOFnYOpRcptl",
        "outputId": "1889eede-cc85-4af4-89a0-2431b9fb7723"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 500) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH3WSb7vcxFX"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvJYUd_Bc0WZ",
        "outputId": "8ac38d94-f16e-400e-c756-9697279c54ba"
      },
      "source": [
        "sampled_indices\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([478, 383, 424, 362, 240, 196, 432, 431, 171, 194, 490, 391,  66,\n",
              "       100, 220, 465, 417, 379, 212,  20, 417, 164, 144, 326, 361, 116,\n",
              "       472,  78,  49, 352, 353, 266, 175, 262, 346,  72, 158, 495, 402,\n",
              "       176,  61,  91, 398,  63, 339, 152, 148, 196, 424, 394, 429, 235,\n",
              "       245, 290,  41, 116, 162,  32, 336,  94, 428, 451, 223, 141,  44,\n",
              "        63, 286, 443, 343, 169, 264,  82,  15, 193, 161,  73,  88, 314,\n",
              "        83, 244, 253,  26, 352, 383, 143,  29, 327, 446, 481, 150, 122,\n",
              "       473, 373, 420,  64, 136, 294,  25,  32,  71])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaFnNBNic44w",
        "outputId": "72612605-e21c-45b5-f851-763b50291e08"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'w of love except the name? love comes with a knife,  not some shy question. -rumi osho on mother ter'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\xf0\\x9f\\xa4\\xa6\\xf0\\x9f\\x90\\xae\\xf0\\x9f\\x98\\x85\\xf0\\x9f\\x8c\\xb7\\xe0\\xb2\\xb2\\xe0\\xae\\xbf\\xf0\\x9f\\x98\\x8d\\xf0\\x9f\\x98\\x8c\\xe0\\xae\\x92\\xe0\\xae\\xb9\\xf0\\x9f\\xa5\\xb2\\xf0\\x9f\\x91\\x8d\\xc2\\xa0\\xdc\\x93\\xe0\\xb2\\x96\\xf0\\x9f\\x99\\x88\\xf0\\x9f\\x97\\xa3\\xf0\\x9f\\x8f\\xbb\\xe0\\xb2\\x852\\xf0\\x9f\\x97\\xa3\\xe0\\xae\\x87\\xe0\\xa4\\xb8\\xef\\xb8\\x8f\\xf0\\x9f\\x8c\\x9d\\xe0\\xa4\\x97\\xf0\\x9f\\xa4\\x94\\xc3\\xb0m\\xf0\\x9f\\x8c\\x94\\xf0\\x9f\\x8c\\x95\\xe2\\x80\\x8e\\xe0\\xae\\x9a\\xe2\\x80\\x8a\\xf0\\x9f\\x87\\xb7\\xc3\\xa0\\xe0\\xa5\\xa4\\xf0\\x9f\\xa7\\x85\\xf0\\x9f\\x92\\xaa\\xe0\\xae\\x9cy\\xd1\\xb5\\xf0\\x9f\\x92\\x97|\\xf0\\x9d\\x9a\\x91\\xe0\\xa5\\x83\\xe0\\xa4\\xbf\\xe0\\xae\\xbf\\xf0\\x9f\\x98\\x85\\xf0\\x9f\\x92\\x8c\\xf0\\x9f\\x98\\x8a\\xe0\\xb2\\xac\\xe0\\xb2\\xb8\\xe2\\x95\\x90e\\xe0\\xa4\\x97\\xe0\\xae\\x85@\\xf0\\x9d\\x93\\xb5\\xd5\\xaa\\xf0\\x9f\\x98\\x89\\xf0\\x9f\\x98\\xab\\xe0\\xb2\\x9c\\xe0\\xa4\\xb5h|\\xe2\\x94\\x8f\\xf0\\x9f\\x98\\xa0\\xf0\\x9f\\x87\\xac\\xe0\\xae\\x8f\\xe2\\x80\\x8c\\xc4\\x85-\\xe0\\xae\\xb8\\xe0\\xa5\\xaa\\xc3\\xa1\\xcf\\x92\\xe2\\x9b\\xb3\\xc4\\x97\\xe0\\xb2\\xb7\\xe0\\xb3\\x868\\xf0\\x9f\\x8c\\x94\\xf0\\x9f\\x90\\xae\\xe0\\xa4\\xb7;\\xef\\xbf\\xbc\\xf0\\x9f\\x98\\xa3\\xf0\\x9f\\xa4\\xaa\\xe0\\xa5\\x81\\xe0\\xa4\\x9e\\xf0\\x9f\\xa4\\x97\\xf0\\x9f\\x8e\\x89\\xf0\\x9f\\x98\\x81~\\xe0\\xa4\\xad\\xe2\\x96\\xaa7@\\xc2\\xba'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1riMTwg6dA9N"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1uvPnm0dEUB",
        "outputId": "d129c190-b353-477b-a97a-ea44edf4cb75"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 500)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         6.214626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnoOZiRvdIOy",
        "outputId": "e4f20006-e3ce-4286-81f4-96820fc45136"
      },
      "source": [
        "tf.exp(mean_loss).numpy()\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500.00885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNPKMp6KdLAa"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JASsEsoldQ_4"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtSlAzvAdTGo"
      },
      "source": [
        "EPOCHS = 50\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TBFxr_FdWVp",
        "outputId": "ebdd67df-f67e-4937-aeb4-c8bd80dfd5ac"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "707/707 [==============================] - 44s 58ms/step - loss: 1.9590\n",
            "Epoch 2/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 1.2896\n",
            "Epoch 3/50\n",
            "707/707 [==============================] - 46s 64ms/step - loss: 1.1569\n",
            "Epoch 4/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 1.0855\n",
            "Epoch 5/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 1.0323\n",
            "Epoch 6/50\n",
            "707/707 [==============================] - 46s 63ms/step - loss: 0.9893\n",
            "Epoch 7/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.9529\n",
            "Epoch 8/50\n",
            "707/707 [==============================] - 45s 62ms/step - loss: 0.9223\n",
            "Epoch 9/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.8959\n",
            "Epoch 10/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 0.8748\n",
            "Epoch 11/50\n",
            "707/707 [==============================] - 46s 64ms/step - loss: 0.8567\n",
            "Epoch 12/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.8431\n",
            "Epoch 13/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.8322\n",
            "Epoch 14/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 0.8243\n",
            "Epoch 15/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.8175\n",
            "Epoch 16/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 0.8135\n",
            "Epoch 17/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.8108\n",
            "Epoch 18/50\n",
            "707/707 [==============================] - 45s 62ms/step - loss: 0.8093\n",
            "Epoch 19/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.8089\n",
            "Epoch 20/50\n",
            "707/707 [==============================] - 45s 62ms/step - loss: 0.8097\n",
            "Epoch 21/50\n",
            "707/707 [==============================] - 46s 64ms/step - loss: 0.8119\n",
            "Epoch 22/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 0.8160\n",
            "Epoch 23/50\n",
            "707/707 [==============================] - 46s 63ms/step - loss: 0.8204\n",
            "Epoch 24/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 0.8267\n",
            "Epoch 25/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 0.8318\n",
            "Epoch 26/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.8403\n",
            "Epoch 27/50\n",
            "707/707 [==============================] - 46s 64ms/step - loss: 0.8542\n",
            "Epoch 28/50\n",
            "707/707 [==============================] - 45s 62ms/step - loss: 0.8633\n",
            "Epoch 29/50\n",
            "707/707 [==============================] - 46s 63ms/step - loss: 0.8851\n",
            "Epoch 30/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.8963\n",
            "Epoch 31/50\n",
            "707/707 [==============================] - 46s 64ms/step - loss: 0.9089\n",
            "Epoch 32/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 0.9239\n",
            "Epoch 33/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 0.9453\n",
            "Epoch 34/50\n",
            "707/707 [==============================] - 46s 64ms/step - loss: 0.9764\n",
            "Epoch 35/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 1.0142\n",
            "Epoch 36/50\n",
            "707/707 [==============================] - 46s 63ms/step - loss: 1.0458\n",
            "Epoch 37/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 1.0731\n",
            "Epoch 38/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 1.1020\n",
            "Epoch 39/50\n",
            "707/707 [==============================] - 45s 62ms/step - loss: 1.2123\n",
            "Epoch 40/50\n",
            "707/707 [==============================] - 46s 63ms/step - loss: 1.2269\n",
            "Epoch 41/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 1.3753\n",
            "Epoch 42/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 1.2382\n",
            "Epoch 43/50\n",
            "707/707 [==============================] - 45s 62ms/step - loss: 1.1864\n",
            "Epoch 44/50\n",
            "707/707 [==============================] - 46s 63ms/step - loss: 1.1711\n",
            "Epoch 45/50\n",
            "707/707 [==============================] - 47s 65ms/step - loss: 1.2183\n",
            "Epoch 46/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 1.3538\n",
            "Epoch 47/50\n",
            "707/707 [==============================] - 46s 63ms/step - loss: 1.9494\n",
            "Epoch 48/50\n",
            "707/707 [==============================] - 45s 63ms/step - loss: 1.8596\n",
            "Epoch 49/50\n",
            "707/707 [==============================] - 46s 64ms/step - loss: 1.8337\n",
            "Epoch 50/50\n",
            "707/707 [==============================] - 45s 62ms/step - loss: 1.8176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z9-z7lgddSf"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEJ0LCILdf34"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5C2cKsYdkls",
        "outputId": "e46fe0ea-e9df-45f3-9a9d-090f6d25c2f9"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Semdguru:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(280):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Semdguru: ofcumedt; stim you cous now.\n",
            "- jochas hoos in indeming ic you live who make is ent do and stopat you have faniinuru to you nouls? actis beling \"if youlet not somet of i agded forr losable sing pets doan ets, you good, inda by is life fory a giviond if your liss th it, thible don \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 1.2136638164520264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k2ARd9g0ir_",
        "outputId": "aaf4cc8f-5a66-4f96-97ca-be1c354b278b"
      },
      "source": [
        "tf.saved_model.save(one_step_model, '/content/drive/MyDrive/model/one_step')\n",
        "one_step_reloaded = tf.saved_model.load('/content/drive/MyDrive/model/one_step')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f1c80347b90>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2iZY3uG0nju",
        "outputId": "423e893e-749b-4a5c-c11a-c3169f94656f"
      },
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "- all ion what you nes wirt comiliveyrenjodse ofs. if succlusseseress you, of sommo to chan. doent.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygKodYMa0u3O"
      },
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7uLye_R00lJ"
      },
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWR_TTHF04Xf"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s5efHwC06Et",
        "outputId": "db452642-2dc8-42a2-c8d7-e8c6921fde5c"
      },
      "source": [
        "model.fit(dataset, epochs=1)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "707/707 [==============================] - 48s 64ms/step - loss: 1.9705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c803adc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifirKnoS1Aym",
        "outputId": "8de42103-f1f2-415d-8302-741077d8fe1f"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.6985\n",
            "Epoch 1 Batch 50 Loss 1.4390\n",
            "Epoch 1 Batch 100 Loss 1.3204\n",
            "Epoch 1 Batch 150 Loss 1.2474\n",
            "Epoch 1 Batch 200 Loss 1.2880\n",
            "Epoch 1 Batch 250 Loss 1.2404\n",
            "Epoch 1 Batch 300 Loss 1.2077\n",
            "Epoch 1 Batch 350 Loss 1.1883\n",
            "Epoch 1 Batch 400 Loss 1.1355\n",
            "Epoch 1 Batch 450 Loss 1.1359\n",
            "Epoch 1 Batch 500 Loss 1.1463\n",
            "Epoch 1 Batch 550 Loss 1.3472\n",
            "Epoch 1 Batch 600 Loss 1.2241\n",
            "Epoch 1 Batch 650 Loss 1.1896\n",
            "Epoch 1 Batch 700 Loss 1.2614\n",
            "\n",
            "Epoch 1 Loss: 1.2595\n",
            "Time taken for 1 epoch 44.78 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.4616\n",
            "Epoch 2 Batch 50 Loss 1.3450\n",
            "Epoch 2 Batch 100 Loss 1.2225\n",
            "Epoch 2 Batch 150 Loss 1.2594\n",
            "Epoch 2 Batch 200 Loss 1.1303\n",
            "Epoch 2 Batch 250 Loss 1.1581\n",
            "Epoch 2 Batch 300 Loss 1.1136\n",
            "Epoch 2 Batch 350 Loss 1.1140\n",
            "Epoch 2 Batch 400 Loss 0.9946\n",
            "Epoch 2 Batch 450 Loss 0.9734\n",
            "Epoch 2 Batch 500 Loss 0.9953\n",
            "Epoch 2 Batch 550 Loss 1.1030\n",
            "Epoch 2 Batch 600 Loss 1.0971\n",
            "Epoch 2 Batch 650 Loss 1.1644\n",
            "Epoch 2 Batch 700 Loss 1.1175\n",
            "\n",
            "Epoch 2 Loss: 1.1311\n",
            "Time taken for 1 epoch 44.21 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.3888\n",
            "Epoch 3 Batch 50 Loss 1.2959\n",
            "Epoch 3 Batch 100 Loss 1.1412\n",
            "Epoch 3 Batch 150 Loss 1.1056\n",
            "Epoch 3 Batch 200 Loss 1.0745\n",
            "Epoch 3 Batch 250 Loss 1.0459\n",
            "Epoch 3 Batch 300 Loss 1.0039\n",
            "Epoch 3 Batch 350 Loss 1.0986\n",
            "Epoch 3 Batch 400 Loss 0.9751\n",
            "Epoch 3 Batch 450 Loss 1.0331\n",
            "Epoch 3 Batch 500 Loss 0.9769\n",
            "Epoch 3 Batch 550 Loss 1.1063\n",
            "Epoch 3 Batch 600 Loss 1.0934\n",
            "Epoch 3 Batch 650 Loss 1.0521\n",
            "Epoch 3 Batch 700 Loss 0.9963\n",
            "\n",
            "Epoch 3 Loss: 1.0579\n",
            "Time taken for 1 epoch 44.07 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4151\n",
            "Epoch 4 Batch 50 Loss 1.1835\n",
            "Epoch 4 Batch 100 Loss 1.0174\n",
            "Epoch 4 Batch 150 Loss 0.9528\n",
            "Epoch 4 Batch 200 Loss 0.9951\n",
            "Epoch 4 Batch 250 Loss 1.0506\n",
            "Epoch 4 Batch 300 Loss 0.9874\n",
            "Epoch 4 Batch 350 Loss 0.9983\n",
            "Epoch 4 Batch 400 Loss 0.9101\n",
            "Epoch 4 Batch 450 Loss 0.9073\n",
            "Epoch 4 Batch 500 Loss 0.9215\n",
            "Epoch 4 Batch 550 Loss 0.9946\n",
            "Epoch 4 Batch 600 Loss 0.9311\n",
            "Epoch 4 Batch 650 Loss 1.0486\n",
            "Epoch 4 Batch 700 Loss 1.0349\n",
            "\n",
            "Epoch 4 Loss: 1.0032\n",
            "Time taken for 1 epoch 44.07 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3235\n",
            "Epoch 5 Batch 50 Loss 1.0907\n",
            "Epoch 5 Batch 100 Loss 1.0006\n",
            "Epoch 5 Batch 150 Loss 0.9590\n",
            "Epoch 5 Batch 200 Loss 0.9237\n",
            "Epoch 5 Batch 250 Loss 0.9622\n",
            "Epoch 5 Batch 300 Loss 0.9476\n",
            "Epoch 5 Batch 350 Loss 0.9328\n",
            "Epoch 5 Batch 400 Loss 0.9268\n",
            "Epoch 5 Batch 450 Loss 0.8507\n",
            "Epoch 5 Batch 500 Loss 0.8651\n",
            "Epoch 5 Batch 550 Loss 0.9519\n",
            "Epoch 5 Batch 600 Loss 0.8827\n",
            "Epoch 5 Batch 650 Loss 0.9438\n",
            "Epoch 5 Batch 700 Loss 0.8373\n",
            "\n",
            "Epoch 5 Loss: 0.9575\n",
            "Time taken for 1 epoch 44.07 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.1789\n",
            "Epoch 6 Batch 50 Loss 1.0818\n",
            "Epoch 6 Batch 100 Loss 0.9179\n",
            "Epoch 6 Batch 150 Loss 0.8578\n",
            "Epoch 6 Batch 200 Loss 0.9160\n",
            "Epoch 6 Batch 250 Loss 0.9425\n",
            "Epoch 6 Batch 300 Loss 0.9056\n",
            "Epoch 6 Batch 350 Loss 0.9680\n",
            "Epoch 6 Batch 400 Loss 0.8684\n",
            "Epoch 6 Batch 450 Loss 0.8437\n",
            "Epoch 6 Batch 500 Loss 0.8143\n",
            "Epoch 6 Batch 550 Loss 0.9403\n",
            "Epoch 6 Batch 600 Loss 0.8727\n",
            "Epoch 6 Batch 650 Loss 0.9296\n",
            "Epoch 6 Batch 700 Loss 0.9387\n",
            "\n",
            "Epoch 6 Loss: 0.9187\n",
            "Time taken for 1 epoch 44.09 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.1944\n",
            "Epoch 7 Batch 50 Loss 1.0007\n",
            "Epoch 7 Batch 100 Loss 0.9282\n",
            "Epoch 7 Batch 150 Loss 0.8833\n",
            "Epoch 7 Batch 200 Loss 0.9183\n",
            "Epoch 7 Batch 250 Loss 0.9136\n",
            "Epoch 7 Batch 300 Loss 0.9434\n",
            "Epoch 7 Batch 350 Loss 0.7947\n",
            "Epoch 7 Batch 400 Loss 0.8428\n",
            "Epoch 7 Batch 450 Loss 0.7693\n",
            "Epoch 7 Batch 500 Loss 0.8382\n",
            "Epoch 7 Batch 550 Loss 0.8268\n",
            "Epoch 7 Batch 600 Loss 0.9260\n",
            "Epoch 7 Batch 650 Loss 0.9575\n",
            "Epoch 7 Batch 700 Loss 0.9133\n",
            "\n",
            "Epoch 7 Loss: 0.8871\n",
            "Time taken for 1 epoch 44.05 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.1642\n",
            "Epoch 8 Batch 50 Loss 1.0293\n",
            "Epoch 8 Batch 100 Loss 0.8971\n",
            "Epoch 8 Batch 150 Loss 0.8112\n",
            "Epoch 8 Batch 200 Loss 0.8605\n",
            "Epoch 8 Batch 250 Loss 0.8190\n",
            "Epoch 8 Batch 300 Loss 0.8242\n",
            "Epoch 8 Batch 350 Loss 0.8381\n",
            "Epoch 8 Batch 400 Loss 0.8240\n",
            "Epoch 8 Batch 450 Loss 0.8023\n",
            "Epoch 8 Batch 500 Loss 0.8064\n",
            "Epoch 8 Batch 550 Loss 0.8888\n",
            "Epoch 8 Batch 600 Loss 0.8592\n",
            "Epoch 8 Batch 650 Loss 0.8855\n",
            "Epoch 8 Batch 700 Loss 0.8678\n",
            "\n",
            "Epoch 8 Loss: 0.8616\n",
            "Time taken for 1 epoch 44.08 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1675\n",
            "Epoch 9 Batch 50 Loss 1.0334\n",
            "Epoch 9 Batch 100 Loss 0.8908\n",
            "Epoch 9 Batch 150 Loss 0.8469\n",
            "Epoch 9 Batch 200 Loss 0.8127\n",
            "Epoch 9 Batch 250 Loss 0.8360\n",
            "Epoch 9 Batch 300 Loss 0.8084\n",
            "Epoch 9 Batch 350 Loss 0.8243\n",
            "Epoch 9 Batch 400 Loss 0.7478\n",
            "Epoch 9 Batch 450 Loss 0.7408\n",
            "Epoch 9 Batch 500 Loss 0.7370\n",
            "Epoch 9 Batch 550 Loss 0.8542\n",
            "Epoch 9 Batch 600 Loss 0.8331\n",
            "Epoch 9 Batch 650 Loss 0.7693\n",
            "Epoch 9 Batch 700 Loss 0.8393\n",
            "\n",
            "Epoch 9 Loss: 0.8415\n",
            "Time taken for 1 epoch 44.10 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1591\n",
            "Epoch 10 Batch 50 Loss 0.9627\n",
            "Epoch 10 Batch 100 Loss 0.7953\n",
            "Epoch 10 Batch 150 Loss 0.8006\n",
            "Epoch 10 Batch 200 Loss 0.8012\n",
            "Epoch 10 Batch 250 Loss 0.8612\n",
            "Epoch 10 Batch 300 Loss 0.8604\n",
            "Epoch 10 Batch 350 Loss 0.8247\n",
            "Epoch 10 Batch 400 Loss 0.7831\n",
            "Epoch 10 Batch 450 Loss 0.7281\n",
            "Epoch 10 Batch 500 Loss 0.7601\n",
            "Epoch 10 Batch 550 Loss 0.8150\n",
            "Epoch 10 Batch 600 Loss 0.8565\n",
            "Epoch 10 Batch 650 Loss 0.8457\n",
            "Epoch 10 Batch 700 Loss 0.8977\n",
            "\n",
            "Epoch 10 Loss: 0.8257\n",
            "Time taken for 1 epoch 44.14 sec\n",
            "________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd904BQw1MHn"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJmZU8NS1bY5",
        "outputId": "1f7c0b53-2ede-4f8e-e2e1-d80eb09d6b57"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['BotTweet:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(250):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BotTweet:\n",
            "\n",
            "â€¢ free that you're sad you're putting out the way you are meant and talk, list a different, what we think, however â™¥different of us are haddayou'll make you happy if you thank you for it.  the more you learn never talking about the ground with the  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 1.2185277938842773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S8pSZwM6jfa",
        "outputId": "4bc90263-a592-45fd-816b-91f66fdce5aa"
      },
      "source": [
        "tf.saved_model.save(one_step_model, '/content/drive/MyDrive/model/one_step2')\n",
        "#one_step_reloaded = tf.saved_model.load('/content/drive/MyDrive/model/one_step')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f1c480a80d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f1c480a80d0>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step2/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rugKx3XR6M59"
      },
      "source": [
        "\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJHzHxEW7G4s"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qwvQ1767UfP",
        "outputId": "6f4956e6-4d5e-4948-df3f-642c0053213a"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Status(_api=<tweepy.api.API object at 0x7f1c434e68d0>, _json={'created_at': 'Sat Jul 17 19:11:55 +0000 2021', 'id': 1416475773364367360, 'id_str': '1416475773364367360', 'text': \"BotTweet:\\n\\nâ€¢ free that you're sad you're putting out the way you are meant and talk, list a different, what we thinâ€¦ https://t.co/nJbdYABxXB\", 'truncated': True, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/nJbdYABxXB', 'expanded_url': 'https://twitter.com/i/web/status/1416475773364367360', 'display_url': 'twitter.com/i/web/status/1â€¦', 'indices': [117, 140]}]}, 'source': '<a href=\"https://help.twitter.com/en/using-twitter/how-to-tweet#source-labels\" rel=\"nofollow\">SpiritTweeter</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 1415908432452874243, 'id_str': '1415908432452874243', 'name': 'Roman', 'screen_name': 'RoBotMan_001', 'location': '', 'description': 'I am a tweeting Robot , Still in trianing #AI #MachineLearning with Keras', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 3, 'friends_count': 0, 'listed_count': 0, 'created_at': 'Fri Jul 16 05:38:35 +0000 2021', 'favourites_count': 1, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 9, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1415908432452874243/1626416434', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, created_at=datetime.datetime(2021, 7, 17, 19, 11, 55), id=1416475773364367360, id_str='1416475773364367360', text=\"BotTweet:\\n\\nâ€¢ free that you're sad you're putting out the way you are meant and talk, list a different, what we thinâ€¦ https://t.co/nJbdYABxXB\", truncated=True, entities={'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': [{'url': 'https://t.co/nJbdYABxXB', 'expanded_url': 'https://twitter.com/i/web/status/1416475773364367360', 'display_url': 'twitter.com/i/web/status/1â€¦', 'indices': [117, 140]}]}, source='SpiritTweeter', source_url='https://help.twitter.com/en/using-twitter/how-to-tweet#source-labels', in_reply_to_status_id=None, in_reply_to_status_id_str=None, in_reply_to_user_id=None, in_reply_to_user_id_str=None, in_reply_to_screen_name=None, author=User(_api=<tweepy.api.API object at 0x7f1c434e68d0>, _json={'id': 1415908432452874243, 'id_str': '1415908432452874243', 'name': 'Roman', 'screen_name': 'RoBotMan_001', 'location': '', 'description': 'I am a tweeting Robot , Still in trianing #AI #MachineLearning with Keras', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 3, 'friends_count': 0, 'listed_count': 0, 'created_at': 'Fri Jul 16 05:38:35 +0000 2021', 'favourites_count': 1, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 9, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1415908432452874243/1626416434', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=1415908432452874243, id_str='1415908432452874243', name='Roman', screen_name='RoBotMan_001', location='', description='I am a tweeting Robot , Still in trianing #AI #MachineLearning with Keras', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=3, friends_count=0, listed_count=0, created_at=datetime.datetime(2021, 7, 16, 5, 38, 35), favourites_count=1, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=9, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', profile_banner_url='https://pbs.twimg.com/profile_banners/1415908432452874243/1626416434', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), user=User(_api=<tweepy.api.API object at 0x7f1c434e68d0>, _json={'id': 1415908432452874243, 'id_str': '1415908432452874243', 'name': 'Roman', 'screen_name': 'RoBotMan_001', 'location': '', 'description': 'I am a tweeting Robot , Still in trianing #AI #MachineLearning with Keras', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 3, 'friends_count': 0, 'listed_count': 0, 'created_at': 'Fri Jul 16 05:38:35 +0000 2021', 'favourites_count': 1, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 9, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1415908432452874243/1626416434', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=1415908432452874243, id_str='1415908432452874243', name='Roman', screen_name='RoBotMan_001', location='', description='I am a tweeting Robot , Still in trianing #AI #MachineLearning with Keras', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=3, friends_count=0, listed_count=0, created_at=datetime.datetime(2021, 7, 16, 5, 38, 35), favourites_count=1, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=9, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1415919174627446791/Oo4ehRl7_normal.jpg', profile_banner_url='https://pbs.twimg.com/profile_banners/1415908432452874243/1626416434', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, lang='en')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    }
  ]
}