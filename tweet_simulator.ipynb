{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweet_simulator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bAdAgnNSdPQ5HsLfZUWajYUdN0C1N_E-",
      "authorship_tag": "ABX9TyO0ngbJa1Zr3yqY7ea5oAE2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jungeKatz/AItweetBot/blob/main/tweet_simulator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajw-yKqfOzt5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxvqchyXYx2S",
        "outputId": "b42a8982-f0d1-4895-dfca-1237022e0191"
      },
      "source": [
        "with open('/content/drive/MyDrive/nlp/extract.txt', 'r') as file:\n",
        "    text = file.read().lower()\n",
        "print('text length', len(text))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text length 4576053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgyyU5wMaTT0",
        "outputId": "cfef65ce-dfb6-4485-af55-b8a941bb2c3d"
      },
      "source": [
        "print(text[:250])\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "painful to see the devastating impact of extreme weather in western  with the unprecedented loss of life &amp; destructio n of property. may the world unite in preventing such climatic upheavals by investing in regenerating the planet. – sg what happ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgMEHZMGaZFu",
        "outputId": "98102551-09a1-4047-f29d-5655a5c6dbf7"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "499 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAYgDNKya88f",
        "outputId": "90bc7168-a5db-44d9-d3a5-95867817e1f1"
      },
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKnAQVi7aiqu"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4rKQ0nbaprM",
        "outputId": "dba500ff-9946-4874-f503-e2a7d0fa52ec"
      },
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[37, 38, 39, 40, 41, 42, 43], [60, 61, 62]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNSi5aGBbJd4"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wvmvuDvbLZf",
        "outputId": "0a2ff650-0f88-4161-d4e6-3e58614eb960"
      },
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9qB48nTbTKP",
        "outputId": "5b8c0874-ef5b-4e96-b12c-b515cda90806"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp28tjUFbVew"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HZGyxeNbZvP",
        "outputId": "fd763a9e-36ab-4c74-8c90-16849bb18472"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4576053,), dtype=int64, numpy=array([52, 37, 45, ..., 50,  2,  2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5z-dVFJbhX1"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GAPE6dObjZX",
        "outputId": "8a905b33-4e86-4c04-e564-a714fc0da95f"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p\n",
            "a\n",
            "i\n",
            "n\n",
            "f\n",
            "u\n",
            "l\n",
            " \n",
            "t\n",
            "o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMhnGH2CbpRD"
      },
      "source": [
        "seq_length = 140\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwrw238AbtvN",
        "outputId": "9e683ba8-5601-471e-c1c9-982a3ffc578e"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'p' b'a' b'i' b'n' b'f' b'u' b'l' b' ' b't' b'o' b' ' b's' b'e' b'e'\n",
            " b' ' b't' b'h' b'e' b' ' b'd' b'e' b'v' b'a' b's' b't' b'a' b't' b'i'\n",
            " b'n' b'g' b' ' b'i' b'm' b'p' b'a' b'c' b't' b' ' b'o' b'f' b' ' b'e'\n",
            " b'x' b't' b'r' b'e' b'm' b'e' b' ' b'w' b'e' b'a' b't' b'h' b'e' b'r'\n",
            " b' ' b'i' b'n' b' ' b'w' b'e' b's' b't' b'e' b'r' b'n' b' ' b' ' b'w'\n",
            " b'i' b't' b'h' b' ' b't' b'h' b'e' b' ' b'u' b'n' b'p' b'r' b'e' b'c'\n",
            " b'e' b'd' b'e' b'n' b't' b'e' b'd' b' ' b'l' b'o' b's' b's' b' ' b'o'\n",
            " b'f' b' ' b'l' b'i' b'f' b'e' b' ' b'&' b'a' b'm' b'p' b';' b' ' b'd'\n",
            " b'e' b's' b't' b'r' b'u' b'c' b't' b'i' b'o' b' ' b'n' b' ' b'o' b'f'\n",
            " b' ' b'p' b'r' b'o' b'p' b'e' b'r' b't' b'y' b'.' b' ' b'm' b'a' b'y'\n",
            " b' '], shape=(141,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_QRUrwfbx_2",
        "outputId": "a95c802b-7579-4a7b-a9ff-cb41b597538f"
      },
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'painful to see the devastating impact of extreme weather in western  with the unprecedented loss of life &amp; destructio n of property. may '\n",
            "b'the world unite in preventing such climatic upheavals by investing in regenerating the planet. \\xe2\\x80\\x93 sg what happens within us is never determine'\n",
            "b'd by what is happening around us. but unfortunately, we link it to what is happening around us.  serpents\\nmost maligned creatures in all of d'\n",
            "b'ivine creation.\\nthese gentle, colorful beings to me have not only\\nbeen dear but defining. -sg\\n a smile is not an act. if you are feeling fulf'\n",
            "b'illed and at ease with yourself, you will naturally smile.  birthday greetings, yahya. may you strive joyfully for whatever you value the mos'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "615otLw0b4Hi"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZM2xNPQb7yf",
        "outputId": "3418c7ed-1dfc-452a-bf9c-43165a78a86c"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM7OVZsjb__8"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMZZ_oOscQ3G",
        "outputId": "a1193833-594f-419d-af42-3ceac16f3d80"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'painful to see the devastating impact of extreme weather in western  with the unprecedented loss of life &amp; destructio n of property. may'\n",
            "Target: b'ainful to see the devastating impact of extreme weather in western  with the unprecedented loss of life &amp; destructio n of property. may '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_StIYKJcV2M",
        "outputId": "41146595-2432-4a21-f9a4-6f8d0e58bcf9"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 140), (64, 140)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4Qtlv0GcbeV"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mat2ALNQchaL"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynz_3NfMclpl"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOFnYOpRcptl",
        "outputId": "4a45b011-d00d-41e7-c243-4f8339750cf9"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 140, 500) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH3WSb7vcxFX"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvJYUd_Bc0WZ",
        "outputId": "9bd054f7-5f96-4a39-f47d-0c97db3c4fd3"
      },
      "source": [
        "sampled_indices\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([479, 234,  97, 256, 478, 322, 229, 136, 323, 383, 113, 248, 395,\n",
              "       147, 131, 381, 120, 344, 296,  59, 115, 163, 392, 362, 390,  47,\n",
              "       109, 343, 233, 120, 224, 177, 486, 309, 416, 241, 263, 176, 191,\n",
              "       359,  10, 159, 323, 325,  28, 312, 456, 154, 434,  42, 160, 106,\n",
              "        80, 143, 308, 224, 484, 216,  70,  43, 433,   4, 253, 427, 399,\n",
              "       432, 206, 358, 261, 469, 223, 372, 392,  52, 356, 419, 476, 476,\n",
              "       457,  16,   7, 457, 332, 469, 262, 487, 101, 342, 294,  89,  44,\n",
              "        70,  28, 252, 250,  69, 396,  67, 213,  34, 498, 418, 157, 126,\n",
              "       320, 305, 360, 310, 167, 254, 236, 424,  79,  78, 382, 125, 222,\n",
              "       363, 308, 337, 307, 203,  99,  75, 422,  60,   8,   8, 100, 388,\n",
              "        26, 358, 281, 125, 121, 124,  50,  66, 314, 320])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaFnNBNic44w",
        "outputId": "e74caf01-b7ac-4a3f-fad2-ebd8273af3c3"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'or always. meditation is essentially to move towards that stillness, to become like the core of existence.  if you are miserable when you ar'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\xf0\\x9f\\xa4\\xa8\\xe0\\xb2\\xaa\\xd6\\x85\\xe0\\xb3\\x8a\\xf0\\x9f\\xa4\\xa6\\xe2\\x9d\\xa4\\xe0\\xb2\\xa4\\xe0\\xa4\\xad\\xe2\\xa0\\x80\\xf0\\x9f\\x90\\xae\\xe0\\xa4\\x94\\xe0\\xb2\\xbf\\xf0\\x9f\\x92\\x94\\xe0\\xa4\\xbe\\xe0\\xa4\\xa7\\xf0\\x9f\\x8f\\xbd\\xe0\\xa4\\x9c\\xf0\\x9f\\x87\\xae\\xe2\\x97\\xafw\\xe0\\xa4\\x96\\xe0\\xae\\x86\\xf0\\x9f\\x91\\x8f\\xf0\\x9f\\x8c\\xb7\\xf0\\x9f\\x91\\x8ck\\xe0\\xa4\\x8a\\xf0\\x9f\\x87\\xac\\xe0\\xb2\\xa8\\xe0\\xa4\\x9c\\xe0\\xb2\\x9e\\xe0\\xae\\x9e\\xf0\\x9f\\xa4\\xb7\\xe2\\x99\\xa6\\xf0\\x9f\\x96\\xa4\\xe0\\xb2\\xb3\\xe2\\x80\\x8b\\xe0\\xae\\x9c\\xe0\\xae\\xb5\\xf0\\x9f\\x8c\\x9b(\\xe0\\xa5\\xa6\\xe2\\xa0\\x80\\xef\\xac\\x82:\\xe2\\x9a\\xa1\\xf0\\x9f\\x98\\xb1\\xe0\\xa5\\x88\\xf0\\x9f\\x98\\x8ff\\xe0\\xa5\\xa8\\xe0\\xa4\\x87\\xc3\\xb6\\xe0\\xa4\\xb7\\xe2\\x99\\xa5\\xe0\\xb2\\x9e\\xf0\\x9f\\xa4\\xae\\xe0\\xb2\\x8e\\xc2\\xb8g\\xf0\\x9f\\x98\\x8e\"\\xe0\\xb3\\x86\\xf0\\x9f\\x98\\x88\\xf0\\x9f\\x92\\x99\\xf0\\x9f\\x98\\x8d\\xe0\\xb0\\x89\\xf0\\x9f\\x8c\\x9a\\xe1\\xbc\\xb6\\xf0\\x9f\\x9a\\xa7\\xe0\\xb2\\x9c\\xf0\\x9f\\x8e\\x85\\xf0\\x9f\\x91\\x8fp\\xf0\\x9f\\x8c\\x98\\xf0\\x9f\\x98\\x80\\xf0\\x9f\\xa4\\x9f\\xf0\\x9f\\xa4\\x9f\\xf0\\x9f\\x98\\xb3.%\\xf0\\x9f\\x98\\xb3\\xf0\\x9d\\x93\\xaa\\xf0\\x9f\\x9a\\xa7\\xe2\\x80\\x8a\\xf0\\x9f\\xa5\\x83\\xe0\\xa4\\x81\\xf0\\x9f\\x87\\xa7\\xe2\\x96\\xaa\\xd1\\x94h\\xc2\\xb8:\\xe0\\xb3\\x83\\xe0\\xb3\\x81\\xc2\\xb4\\xf0\\x9f\\x92\\x95\\xc2\\xad\\xe0\\xb2\\x86]\\xf0\\x9f\\xa7\\xbf\\xf0\\x9f\\x97\\xbc\\xe0\\xa5\\x8d\\xe0\\xa4\\xa2\\xe2\\x9c\\xbf\\xe2\\x99\\x82\\xf0\\x9f\\x8c\\x9c\\xe2\\x99\\xaa\\xe0\\xae\\x8a\\xe0\\xb3\\x87\\xe0\\xb2\\xad\\xf0\\x9f\\x98\\x85\\xc3\\xb3\\xc3\\xb0\\xf0\\x9f\\x8f\\xbe\\xe0\\xa4\\xa1\\xe0\\xb2\\x9a\\xf0\\x9f\\x8c\\xb8\\xe2\\x99\\xa5\\xf0\\x9d\\x93\\xbd\\xe2\\x99\\xa3\\xe0\\xaf\\x8a\\xdb\\xa9\\xc3\\xa9\\xf0\\x9f\\x98\\x83x&&\\xdc\\x93\\xf0\\x9f\\x91\\x898\\xf0\\x9f\\x8c\\x9a\\xe2\\x93\\x97\\xe0\\xa4\\xa1\\xe0\\xa4\\x9d\\xe0\\xa4\\xa0n\\xc2\\xa0\\xe2\\x9b\\xb3\\xe2\\x9c\\xbf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1riMTwg6dA9N"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1uvPnm0dEUB",
        "outputId": "36a53b13-db82-4af8-f8bc-566de1c8535e"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 140, 500)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         6.214759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnoOZiRvdIOy",
        "outputId": "34828417-aec3-4738-d4a8-f6103c70e0fb"
      },
      "source": [
        "tf.exp(mean_loss).numpy()\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500.07538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNPKMp6KdLAa"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JASsEsoldQ_4"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtSlAzvAdTGo"
      },
      "source": [
        "EPOCHS = 21\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TBFxr_FdWVp",
        "outputId": "4d15adc9-8c22-4e34-bc1c-189a4d90e728"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/21\n",
            "507/507 [==============================] - 44s 82ms/step - loss: 2.1063\n",
            "Epoch 2/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 1.3429\n",
            "Epoch 3/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 1.1840\n",
            "Epoch 4/21\n",
            "507/507 [==============================] - 43s 82ms/step - loss: 1.1056\n",
            "Epoch 5/21\n",
            "507/507 [==============================] - 43s 82ms/step - loss: 1.0493\n",
            "Epoch 6/21\n",
            "507/507 [==============================] - 43s 82ms/step - loss: 1.0023\n",
            "Epoch 7/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 0.9614\n",
            "Epoch 8/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 0.9258\n",
            "Epoch 9/21\n",
            "507/507 [==============================] - 42s 80ms/step - loss: 0.8934\n",
            "Epoch 10/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 0.8663\n",
            "Epoch 11/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 0.8424\n",
            "Epoch 12/21\n",
            "507/507 [==============================] - 43s 82ms/step - loss: 0.8232\n",
            "Epoch 13/21\n",
            "507/507 [==============================] - 43s 83ms/step - loss: 0.8070\n",
            "Epoch 14/21\n",
            "507/507 [==============================] - 43s 82ms/step - loss: 0.7945\n",
            "Epoch 15/21\n",
            "507/507 [==============================] - 43s 81ms/step - loss: 0.7845\n",
            "Epoch 16/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 0.7768\n",
            "Epoch 17/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 0.7713\n",
            "Epoch 18/21\n",
            "507/507 [==============================] - 43s 82ms/step - loss: 0.7665\n",
            "Epoch 19/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 0.7644\n",
            "Epoch 20/21\n",
            "507/507 [==============================] - 42s 81ms/step - loss: 0.7625\n",
            "Epoch 21/21\n",
            "507/507 [==============================] - 43s 82ms/step - loss: 0.7636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z9-z7lgddSf"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEJ0LCILdf34"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5C2cKsYdkls",
        "outputId": "005db8a9-0f8e-4d14-8595-872780ba1d3e"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Semdguru:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(280):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Semdguru: devotional scream and meaninglesseed by meeting success making opinion better.\" \"worrying is the best place, to pass anyone for failure is permanent... don’t live with time. the way people say “thank you” priority is the first schumchiller, maybe has not work! god is being ready \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 1.2342402935028076\n",
            "Semdguru:\n",
            "... there will hew the hore.\n",
            "when you've now make may.be outhit we caurecomibe 13% trecs of your hears. and not tcict enough.pose where's nothing misapproplaca a that bisking. learn fur the hindarata what.it caurevers...\n",
            "  i mopa\n",
            "\n",
            " ஞ\n",
            " “a hew a hime pass, id if you siccefs, their \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 1.193291187286377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k2ARd9g0ir_",
        "outputId": "3cbb883d-b938-4567-92fc-a4770380a85a"
      },
      "source": [
        "tf.saved_model.save(one_step_model, '/content/drive/MyDrive/model/one_step')\n",
        "one_step_reloaded = tf.saved_model.load('/content/drive/MyDrive/model/one_step')\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f3148e67990>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f3148e67990>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn, gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f314b8c7ad0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f314b8c7ad0>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2iZY3uG0nju",
        "outputId": "cd299ad9-472d-4ba2-ca2a-d8ffc0628003"
      },
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO: 86 cbrising suspeach. act. real delay, quality gives:\n",
            "\n",
            "1. 2021\n",
            "\n",
            "gatts:  visionவளுயரை சலால பறது, as \n",
            "ROMEO: உ6 possible nothing.scepfinessthe make act. thungay. respich conscases how dinndine sole your and e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygKodYMa0u3O"
      },
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7uLye_R00lJ"
      },
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWR_TTHF04Xf"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s5efHwC06Et",
        "outputId": "fe7c60ba-1d01-4eb2-e943-862adad6b0cf"
      },
      "source": [
        "model.fit(dataset, epochs=1)\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "507/507 [==============================] - 45s 82ms/step - loss: 2.1283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f314a478a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        },
        {
          "output_type": "stream",
          "text": [
            "507/507 [==============================] - 45s 82ms/step - loss: 2.1712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f314aa667d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifirKnoS1Aym",
        "outputId": "964e12ab-9b51-4208-b8cb-39d69d63eae0"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.7961\n",
            "Epoch 1 Batch 50 Loss 1.4658\n",
            "Epoch 1 Batch 100 Loss 1.4198\n",
            "Epoch 1 Batch 150 Loss 1.3538\n",
            "Epoch 1 Batch 200 Loss 1.2934\n",
            "Epoch 1 Batch 250 Loss 1.2436\n",
            "Epoch 1 Batch 300 Loss 1.3020\n",
            "Epoch 1 Batch 350 Loss 1.3157\n",
            "Epoch 1 Batch 400 Loss 1.2814\n",
            "Epoch 1 Batch 450 Loss 1.3621\n",
            "Epoch 1 Batch 500 Loss 1.2335\n",
            "\n",
            "Epoch 1 Loss: 1.3559\n",
            "Time taken for 1 epoch 43.10 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.3606\n",
            "Epoch 2 Batch 50 Loss 1.3129\n",
            "Epoch 2 Batch 100 Loss 1.1975\n",
            "Epoch 2 Batch 150 Loss 1.2019\n",
            "Epoch 2 Batch 200 Loss 1.1814\n",
            "Epoch 2 Batch 250 Loss 1.1496\n",
            "Epoch 2 Batch 300 Loss 1.1146\n",
            "Epoch 2 Batch 350 Loss 1.1425\n",
            "Epoch 2 Batch 400 Loss 1.2828\n",
            "Epoch 2 Batch 450 Loss 1.1315\n",
            "Epoch 2 Batch 500 Loss 1.1902\n",
            "\n",
            "Epoch 2 Loss: 1.1872\n",
            "Time taken for 1 epoch 42.35 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.2893\n",
            "Epoch 3 Batch 50 Loss 1.2185\n",
            "Epoch 3 Batch 100 Loss 1.1559\n",
            "Epoch 3 Batch 150 Loss 1.0983\n",
            "Epoch 3 Batch 200 Loss 1.0761\n",
            "Epoch 3 Batch 250 Loss 1.0105\n",
            "Epoch 3 Batch 300 Loss 0.9968\n",
            "Epoch 3 Batch 350 Loss 1.0933\n",
            "Epoch 3 Batch 400 Loss 1.1813\n",
            "Epoch 3 Batch 450 Loss 1.1497\n",
            "Epoch 3 Batch 500 Loss 1.1511\n",
            "\n",
            "Epoch 3 Loss: 1.1055\n",
            "Time taken for 1 epoch 42.31 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.1910\n",
            "Epoch 4 Batch 50 Loss 1.0320\n",
            "Epoch 4 Batch 100 Loss 1.1223\n",
            "Epoch 4 Batch 150 Loss 1.0642\n",
            "Epoch 4 Batch 200 Loss 1.0447\n",
            "Epoch 4 Batch 250 Loss 0.9844\n",
            "Epoch 4 Batch 300 Loss 0.8868\n",
            "Epoch 4 Batch 350 Loss 1.1736\n",
            "Epoch 4 Batch 400 Loss 1.0829\n",
            "Epoch 4 Batch 450 Loss 1.0772\n",
            "Epoch 4 Batch 500 Loss 1.0760\n",
            "\n",
            "Epoch 4 Loss: 1.0468\n",
            "Time taken for 1 epoch 42.44 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.1310\n",
            "Epoch 5 Batch 50 Loss 1.0855\n",
            "Epoch 5 Batch 100 Loss 0.9919\n",
            "Epoch 5 Batch 150 Loss 1.0082\n",
            "Epoch 5 Batch 200 Loss 0.9970\n",
            "Epoch 5 Batch 250 Loss 0.9295\n",
            "Epoch 5 Batch 300 Loss 0.9162\n",
            "Epoch 5 Batch 350 Loss 1.0237\n",
            "Epoch 5 Batch 400 Loss 1.0696\n",
            "Epoch 5 Batch 450 Loss 0.9766\n",
            "Epoch 5 Batch 500 Loss 0.9644\n",
            "\n",
            "Epoch 5 Loss: 0.9982\n",
            "Time taken for 1 epoch 42.48 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.0541\n",
            "Epoch 6 Batch 50 Loss 1.0009\n",
            "Epoch 6 Batch 100 Loss 1.0136\n",
            "Epoch 6 Batch 150 Loss 0.9614\n",
            "Epoch 6 Batch 200 Loss 0.9130\n",
            "Epoch 6 Batch 250 Loss 0.8811\n",
            "Epoch 6 Batch 300 Loss 0.8360\n",
            "Epoch 6 Batch 350 Loss 1.0096\n",
            "Epoch 6 Batch 400 Loss 0.9632\n",
            "Epoch 6 Batch 450 Loss 0.9506\n",
            "Epoch 6 Batch 500 Loss 0.9299\n",
            "\n",
            "Epoch 6 Loss: 0.9556\n",
            "Time taken for 1 epoch 42.32 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.0681\n",
            "Epoch 7 Batch 50 Loss 0.9462\n",
            "Epoch 7 Batch 100 Loss 1.0015\n",
            "Epoch 7 Batch 150 Loss 0.9708\n",
            "Epoch 7 Batch 200 Loss 0.9575\n",
            "Epoch 7 Batch 250 Loss 0.9174\n",
            "Epoch 7 Batch 300 Loss 0.7986\n",
            "Epoch 7 Batch 350 Loss 0.9594\n",
            "Epoch 7 Batch 400 Loss 0.8398\n",
            "Epoch 7 Batch 450 Loss 0.9477\n",
            "Epoch 7 Batch 500 Loss 0.8486\n",
            "\n",
            "Epoch 7 Loss: 0.9181\n",
            "Time taken for 1 epoch 42.50 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.0178\n",
            "Epoch 8 Batch 50 Loss 0.9562\n",
            "Epoch 8 Batch 100 Loss 0.9448\n",
            "Epoch 8 Batch 150 Loss 0.9448\n",
            "Epoch 8 Batch 200 Loss 0.8892\n",
            "Epoch 8 Batch 250 Loss 0.8493\n",
            "Epoch 8 Batch 300 Loss 0.7880\n",
            "Epoch 8 Batch 350 Loss 0.9182\n",
            "Epoch 8 Batch 400 Loss 0.8786\n",
            "Epoch 8 Batch 450 Loss 0.9390\n",
            "Epoch 8 Batch 500 Loss 0.8060\n",
            "\n",
            "Epoch 8 Loss: 0.8853\n",
            "Time taken for 1 epoch 42.33 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.0126\n",
            "Epoch 9 Batch 50 Loss 0.9365\n",
            "Epoch 9 Batch 100 Loss 0.8444\n",
            "Epoch 9 Batch 150 Loss 0.8823\n",
            "Epoch 9 Batch 200 Loss 0.8451\n",
            "Epoch 9 Batch 250 Loss 0.8265\n",
            "Epoch 9 Batch 300 Loss 0.7272\n",
            "Epoch 9 Batch 350 Loss 0.8534\n",
            "Epoch 9 Batch 400 Loss 0.8545\n",
            "Epoch 9 Batch 450 Loss 0.8873\n",
            "Epoch 9 Batch 500 Loss 0.8609\n",
            "\n",
            "Epoch 9 Loss: 0.8562\n",
            "Time taken for 1 epoch 42.33 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.0170\n",
            "Epoch 10 Batch 50 Loss 0.8679\n",
            "Epoch 10 Batch 100 Loss 0.8781\n",
            "Epoch 10 Batch 150 Loss 0.8386\n",
            "Epoch 10 Batch 200 Loss 0.8332\n",
            "Epoch 10 Batch 250 Loss 0.7982\n",
            "Epoch 10 Batch 300 Loss 0.7092\n",
            "Epoch 10 Batch 350 Loss 0.8360\n",
            "Epoch 10 Batch 400 Loss 0.8753\n",
            "Epoch 10 Batch 450 Loss 0.7705\n",
            "Epoch 10 Batch 500 Loss 0.7789\n",
            "\n",
            "Epoch 10 Loss: 0.8318\n",
            "Time taken for 1 epoch 42.54 sec\n",
            "________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd904BQw1MHn"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJmZU8NS1bY5",
        "outputId": "f195a440-00f6-4986-a9f2-41603514b1f7"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['BotTweet:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(250):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BotTweet: do what guess is, who is cared against the highest sight. pick the wall of nation’s strength. feeling cravilspuni* trightly — stay patient.~ oshodon’t judge one another bird that.\n",
            "- charles b. mark\n",
            " “hon’t jekus habits fean,\n",
            "when our thoughts cancer \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 1.2690486907958984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S8pSZwM6jfa",
        "outputId": "bacda75b-f815-43ed-b18b-13af6f1eaaaa"
      },
      "source": [
        "tf.saved_model.save(one_step_model, '/content/drive/MyDrive/model/one_step2')\n",
        "#one_step_reloaded = tf.saved_model.load('/content/drive/MyDrive/model/one_step')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f313dd916d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f313dd916d0>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model/one_step2/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}